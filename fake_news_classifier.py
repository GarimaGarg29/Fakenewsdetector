# -*- coding: utf-8
"""fake_news_classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uwYL4nZ7XBCPIFn48lUSv0gbcpdy1hSS
"""

from google.colab import drive
drive.mount('/content/drive')

import nltk
import pandas as pd

df = pd.read_csv('drive/My Drive/fake-news/train.csv')

df

#get the independent features
X = df.drop('label',axis=1)
X

y = df['label']
y

df.shape

df.head(10)

df = df.dropna()

df.shape

df.head(10)

msg = df.copy()

msg.shape

msg.reset_index(inplace= True)

msg.head(10)

#text preprocessing
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer

nltk.download('stopwords')

import re
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
stemmer = PorterStemmer()
corpus = []
for i in range(len(msg)):
  review = re.sub('[^a-zA-Z]',' ',msg['text'][i])
  review = review.lower()
  review = review.split()
  review = [stemmer.stem(word) for word in review if not word in stopwords.words('english')]
  review = ' '.join(review)
  corpus.append(review)

corpus

#creating bag of words model
from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features=5000,ngram_range=(1,3))
X = cv.fit_transform(corpus).toarray()

X

X.shape

y = msg['label']

y

y.shape

#divide the dataset into train and test
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33)

cv.get_feature_names()[:20]

cv.get_params

count_df = pd.DataFrame(X_train, columns=cv.get_feature_names())

count_df

corpus[0]

"""# **MultinomialNB Algorithm**"""

from sklearn.naive_bayes import MultinomialNB
classifier = MultinomialNB()

from sklearn import metrics
classifier.fit(X_train,y_train)
y_pred = classifier.predict(X_test)
score = metrics.accuracy_score(y_test,y_pred)
print("accuracy : %0.3f" % score)

cm = metrics.confusion_matrix(y_test,y_pred)
cm

#this function prints and plot the confusion matrix
import numpy as np
import itertools
import matplotlib.pyplot as plt
def plot_confusion_matrix(cm,classes,normalize=False,title='Confusion Matrix',cmap=plt.cm.Blues):
  plt.imshow(cm,interpolation='nearest',cmap=cmap)
  plt.title(title)
  plt.colorbar()
  tick_marks = np.arange(len(classes))
  plt.xticks(tick_marks,classes,rotation=45)
  plt.yticks(tick_marks,classes)

  if normalize:
    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    print("Normalize Confusion Matrix")
  else:
    print('Confusion matrix, without Normalization')
  thresh = cm.max() / 2.
  for i,j in itertools.product(range(cm.shape[0]),range(cm.shape[1])):
    plt.text(j,i,cm[i,j],horizontalalignment = "center", color = "white" if cm[i,j] > thresh else "black")
  plt.tight_layout()
  plt.ylabel('True values')
  plt.xlabel('Predicted values')

plot_confusion_matrix(cm,classes = ['Fake','Real'])

"""# **Passive Aggressive Classifier Algorithm**"""

from sklearn.linear_model import PassiveAggressiveClassifier

model = PassiveAggressiveClassifier(n_iter_no_change=50)

model.fit(X_train,y_train)
y_pred = model.predict(X_test)
score = metrics.accuracy_score(y_test,y_pred)
print("accuracy : %0.3f" % score)

cm = metrics.confusion_matrix(y_test,y_pred)
cm

plot_confusion_matrix(cm,classes = ['Fake','Real'])

"""# **Multinomial Classifier with Hyperparameter**"""

previous_score = 0
for alpha in np.arange(0,1,0.1):
  sub_classifier = MultinomialNB(alpha=alpha)
  sub_classifier.fit(X_train,y_train)
  y_pred = sub_classifier.predict(X_test)
  score = metrics.accuracy_score(y_pred,y_test)
  if score > previous_score:
    classifier = sub_classifier
  print("Alpha : {}, Score : {}".format(alpha,score))
